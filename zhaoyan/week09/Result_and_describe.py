主要修改点：
1.修改模型（传递掩码attention_mask）
2.使用 BERT tokenizer 编码句子
3.BERT会添加特殊token（[CLS], [SEP]），但标签序列没有对应的标签。需要调整
 
{
"B-LOCATION": 0,
"B-ORGANIZATION": 1,
"B-PERSON": 2,
"B-TIME": 3,
"I-LOCATION": 4,
"I-ORGANIZATION": 5,
"I-PERSON": 6,
"I-TIME": 7,
"O": 8
}
1数据集：词编码后的数字【[CLS] 张 三 [SEP] [PAD] [PAD]】
2BERT掩码【0,1,0,0,0】告诉模型的有效信息位置
3标签：0-8，为空填充的用-1代替,[CLS]和[SEP]用标签8代替，对应【8,2,8,-1,-1】
4CRF的掩码mask：标签大于-1的为true【true,true,true,false,false】
注：CRF要求序列的第一个时间步必须是有效的，即第一个为true，所以[CLS]和[SEP]用标签8代替，不能用-1


2025-12-18 13:52:45,255 - __main__ - INFO - 开始测试第20轮模型效果：
2025-12-18 13:53:09,589 - __main__ - INFO - PERSON类实体，准确率：0.828571, 召回率: 0.751295, F1: 0.788038
2025-12-18 13:53:09,589 - __main__ - INFO - LOCATION类实体，准确率：0.690141, 召回率: 0.622881, F1: 0.654783
2025-12-18 13:53:09,589 - __main__ - INFO - TIME类实体，准确率：0.717791, 召回率: 0.661017, F1: 0.688230
2025-12-18 13:53:09,589 - __main__ - INFO - ORGANIZATION类实体，准确率：0.623762, 召回率: 0.663158, F1: 0.642852
2025-12-18 13:53:09,589 - __main__ - INFO - Macro-F1: 0.693476
2025-12-18 13:53:09,589 - __main__ - INFO - Micro-F1 0.697704
2025-12-18 13:53:09,589 - __main__ - INFO - --------------------
